* 主机解析

`/etc/hosts`
<pre>
192.168.8.145	node
192.168.8.146   node1
192.168.8.194   node2
192.168.8.183   node3
</pre>

## keystone

<pre>
yum install openstack-keystone openstack-utils httpd mod_wsgi python-keystone python-openstackclient memcached python-memcached -y
mysql -uroot -p -h192.168.8.145
CREATE DATABASE keystone;
GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'localhost' IDENTIFIED BY 'keystone';
GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' IDENTIFIED BY 'keystone';
GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'controller' IDENTIFIED BY 'keystone';
openstack-config --set /etc/keystone/keystone.conf database connection mysql+pymysql://keystone:keystone@node/keystone
openstack-config --set /etc/keystone/keystone.conf token provider fernet
openstack-config --set /etc/keystone/keystone.conf DEFAULT admin_token ADMIN_TOKEN
openstack-config --set /etc/keystone/keystone.conf DEFAULT debug true
openstack-config --set /etc/keystone/keystone.conf DEFAULT admin_bind_host $(hostname -i|awk '{print $2}')
openstack-config --set /etc/keystone/keystone.conf DEFAULT public_bind_host $(hostname -i|awk '{print $2}')
keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone
chown -R keystone:keystone /etc/keystone /var/lib/keystone /var/log/keystone
systemctl enable openstack-keystone
systemctl start openstack-keystone
export OS_TOKEN=ADMIN_TOKEN
export OS_URL=http://node:35357/v3
export OS_IDENTITY_API_VERSION=3
openstack service create --name keystone --description "OpenStack Identity" identity
openstack endpoint create --region wuhan identity public http://node:5000/v3
openstack endpoint create --region wuhan identity internal http://node:5000/v3
openstack endpoint create --region wuhan identity admin http://node:35357/v3
openstack role create admin
openstack role create service
openstack role create domain_admin
openstack role create project_admin
openstack role create guest
openstack role create member
export DEFAULT_DOMAIN_ID=`openstack domain create default | grep -w id | awk '{print $4}'`
openstack-config --set /etc/keystone/keystone.conf identity default_domain_id $DEFAULT_DOMAIN_ID
unset DEFAULT_DOMAIN_ID
systemctl restart openstack-keystone
openstack project create --domain default --description "Admin Project" admin
openstack project create --domain default --description "Service Project" service
  
openstack user create --domain default --project admin --project-domain default --password admin admin
openstack role add --domain default --user admin --project-domain default --user-domain default admin --inherited
openstack role add --project admin --user admin --project-domain default --user-domain default admin
unset OS_TOKEN OS_URL
unset OS_URL
unset OS_IDENTITY_API_VERSION
cat >/root/keystone_admin_v3 &lt;&lt; EOF
export OS_PROJECT_DOMAIN_NAME=default
export OS_USER_DOMAIN_NAME=default
export OS_PROJECT_NAME=admin
export OS_USERNAME=admin
export OS_PASSWORD=admin
export OS_AUTH_URL=http://node:35357/v3
export OS_IDENTITY_API_VERSION=3
export OS_IMAGE_API_VERSION=2
export OS_ENDPOINT_TYPE=internal
export OS_INTERFACE=internal
export PS1='[\u@\h \W(keystone_admin_v3)]$'
EOF
source /root/keystone_admin_v3
openstack token issue
scp /root/keystone_admin_v3 node2:/root/
scp /root/keystone_admin_v3 node3:/root/
scp /etc/keystone/keystone.conf node2:/etc/keystone/keystone.conf 
scp /etc/keystone/keystone.conf node3:/etc/keystone/keystone.conf
scp -r /etc/keystone/fernet-keys node3:/etc/keystone 
scp -r /etc/keystone/fernet-keys node2:/etc/keystone 
ssh node2 chown -R keystone:keystone /etc/keystone /var/lib/keystone /var/log/keystone
ssh node3 chown -R keystone:keystone /etc/keystone /var/lib/keystone /var/log/keystone
ssh node2 systemctl enable openstack-keystone
ssh node2 systemctl start openstack-keystone
ssh node3 systemctl enable openstack-keystone
ssh node3 systemctl start openstack-keystone
</pre>

> 复制完配置文件后需要修改每个节点的绑定地址

### 修改 `Haproxy` 配置文件
<pre>
############# keystone_admin_cluster ########
listen keystone_admin_cluster
bind 192.168.8.145:35357
balance  source
option  tcpka
option  httpchk
option  tcplog
server node1 192.168.8.146:35357 check inter 2000 rise 2 fall 5
server node2 192.168.8.194:35357 check inter 2000 rise 2 fall 5
server node3 192.168.8.183:35357 check inter 2000 rise 2 fall 5

listen keystone_public_internal_cluster
bind 192.168.8.145:5000
balance  source
option  tcpka
option  httpchk
option  tcplog
server node1 192.168.8.146:5000 check inter 2000 rise 2 fall 5
server node2 192.168.8.194:5000 check inter 2000 rise 2 fall 5
server node3 192.168.8.183:5000 check inter 2000 rise 2 fall 5
</pre>

## Glance
<pre>
yum install openstack-glance python-glance openstack-utils -y
mysql
CREATE DATABASE glance;
GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' IDENTIFIED BY 'glance';
GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' IDENTIFIED BY 'glance';
GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'node' IDENTIFIED BY 'glance';
openstack service create --name glance  image
openstack endpoint create --region wuhan image public http://node:9292
openstack endpoint create --region wuhan image internal http://node:9292
openstack endpoint create --region wuhan image admin http://node:9292
openstack user create --domain default --project service --project-domain default --password glance glance
openstack role add --project service --user glance --project-domain default --user-domain default admin
openstack-config --set /etc/glance/glance-api.conf DEFAULT show_image_direct_url True
openstack-config --set /etc/glance/glance-api.conf DEFAULT show_multiple_locations True
openstack-config --set /etc/glance/glance-api.conf DEFAULT workers 2
openstack-config --set /etc/glance/glance-api.conf DEFAULT debug True
openstack-config --set /etc/glance/glance-api.conf database connection mysql+pymysql://glance:glance@node/glance
openstack-config --set /etc/glance/glance-api.conf glance_store stores rbd
openstack-config --set /etc/glance/glance-api.conf glance_store rbd_store_pool images
openstack-config --set /etc/glance/glance-api.conf glance_store rbd_store_user glance
openstack-config --set /etc/glance/glance-api.conf glance_store rbd_store_ceph_conf /etc/ceph/ceph.conf
openstack-config --set /etc/glance/glance-api.conf glance_store rbd_store_chunk_size 8
openstack-config --set /etc/glance/glance-api.conf glance_store default_store rbd
openstack-config --set /etc/glance/glance-api.conf keystone_authtoken auth_uri http://node:5000
openstack-config --set /etc/glance/glance-api.conf keystone_authtoken auth_url http://node:35357
openstack-config --set /etc/glance/glance-api.conf keystone_authtoken auth_type password
openstack-config --set /etc/glance/glance-api.conf keystone_authtoken project_domain_name default
openstack-config --set /etc/glance/glance-api.conf keystone_authtoken user_domain_name default
openstack-config --set /etc/glance/glance-api.conf keystone_authtoken project_name service
openstack-config --set /etc/glance/glance-api.conf keystone_authtoken username glance
openstack-config --set /etc/glance/glance-api.conf keystone_authtoken password glance
openstack-config --set /etc/glance/glance-api.conf keystone_authtoken service_token_roles_required true
openstack-config --set /etc/glance/glance-api.conf paste_deploy flavor keystone

openstack-config --set /etc/glance/glance-registry.conf DEFAULT workers 2
openstack-config --set /etc/glance/glance-registry.conf database connection mysql+pymysql://glance:glance@node/glance
openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken auth_uri http://node:5000
openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken auth_url http://node:35357
openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken auth_type password
openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken project_domain_name default
openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken user_domain_name default
openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken project_name service
openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken username glance
openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken password glance
openstack-config --set /etc/glance/glance-registry.conf paste_deploy flavor keystone
</pre>
<pre>
glance-manage db sync
chown -R glance.glance /etc/glance /var/lib/glance /var/log/glance
scp /etc/glance/glance-api.conf node2:/etc/glance/glance-api.conf
scp /etc/glance/glance-api.conf node3:/etc/glance/glance-api.conf
ssh node2 chown -R glance.glance /etc/glance /var/lib/glance /var/log/glance
ssh node3 chown -R glance.glance /etc/glance /var/lib/glance /var/log/glance
for id in openstack-glance-{api,registry};do systemctl enable $id;systemctl start $id;done
ssh node2 for id in openstack-glance-{api,registry};do systemctl enable $id;systemctl start $id;done
ssh node3 for id in openstack-glance-{api,registry};do systemctl enable $id;systemctl start $id;done
glance image-list
wget http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
glance image-create --name cirros --disk-format qcow2 --container-format bare --visibility public --file cirros-0.3.5-x86_64-disk.img
</pre>
<pre>
rabbit_hosts = 192.168.8.146:$rabbit_port, 192.168.8.194:$rabbit_port, 192.168.8.183:$rabbit_port
bind_host = 192.168.8.183
</pre>
## cinder
<pre>
yum install openstack-cinder python-cinder openstack-utils -y
mysql
CREATE DATABASE cinder;
GRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'localhost' IDENTIFIED BY 'cinder';
GRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'%' IDENTIFIED BY 'cinder';
GRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'node' IDENTIFIED BY 'cinder';
openstack service create --name cinderv2 volumev2
openstack endpoint create --region wuhan   volumev2 admin http://node:8776/v2/%\(tenant_id\)s
openstack endpoint create --region wuhan   volumev2 public http://node:8776/v2/%\(tenant_id\)s
openstack endpoint create --region wuhan   volumev2 internal http://node:8776/v2/%\(tenant_id\)s
openstack-config --set /etc/cinder/cinder.conf DEFAULT transport_url rabbit://guest:guest@node
openstack-config --set /etc/cinder/cinder.conf DEFAULT glance_api_version 2
openstack-config --set /etc/cinder/cinder.conf DEFAULT glance_api_servers http://node:9292
openstack-config --set /etc/cinder/cinder.conf DEFAULT default_volume_type ceph
openstack-config --set /etc/cinder/cinder.conf DEFAULT my_ip 192.168.122.1 # 设置为storage_net的ip
openstack-config --set /etc/cinder/cinder.conf DEFAULT osapi_volume_listen 192.168.8.146
openstack-config --set /etc/cinder/cinder.conf DEFAULT enabled_backends ceph
openstack-config --set /etc/cinder/cinder.conf DEFAULT auth_strategy keystone
 
openstack-config --set /etc/cinder/cinder.conf database connection mysql+pymysql://cinder:cinder@node/cinder
 
openstack-config --set /etc/cinder/cinder.conf keystone_authtoken auth_uri http://node:5000
openstack-config --set /etc/cinder/cinder.conf keystone_authtoken auth_url http://node:35357
openstack-config --set /etc/cinder/cinder.conf keystone_authtoken auth_type password
openstack-config --set /etc/cinder/cinder.conf keystone_authtoken project_domain_name default
openstack-config --set /etc/cinder/cinder.conf keystone_authtoken user_domain_name default
openstack-config --set /etc/cinder/cinder.conf keystone_authtoken project_name service
openstack-config --set /etc/cinder/cinder.conf keystone_authtoken username cinder
openstack-config --set /etc/cinder/cinder.conf keystone_authtoken password cinder
openstack-config --set /etc/cinder/cinder.conf oslo_concurrency lock_path /var/lib/cinder/tmp

openstack-config --set /etc/cinder/cinder.conf oslo_messaging_rabbit rabbit_hosts 192.168.8.146:5672,192.168.8.194:5672,192.168.8.183:5672
 
openstack-config --set /etc/cinder/cinder.conf ceph volume_backend_name ceph
openstack-config --set /etc/cinder/cinder.conf ceph rbd_secret_uuid 3947ff89-361e-4622-98fd-48b0b2723a6c
openstack-config --set /etc/cinder/cinder.conf ceph rbd_user cinder
openstack-config --set /etc/cinder/cinder.conf ceph rbd_pool volumes
openstack-config --set /etc/cinder/cinder.conf ceph rbd_ceph_conf /etc/ceph/ceph.conf
openstack-config --set /etc/cinder/cinder.conf ceph recalculate_allocated_capacity=True
openstack-config --set /etc/cinder/cinder.conf ceph recalculate_allocated_capacity True
openstack-config --set /etc/cinder/cinder.conf ceph rbd_max_clone_depth 3
openstack-config --set /etc/cinder/cinder.conf ceph volume_backend_name ceph
openstack-config --set /etc/cinder/cinder.conf ceph rados_connect_timeout -1
openstack-config --set /etc/cinder/cinder.conf ceph volume_driver cinder.volume.drivers.rbd.RBDDriver
openstack-config --set /etc/cinder/cinder.conf ceph rbd_flatten_volume_from_snapshot False
openstack-config --set /etc/cinder/cinder.conf ceph rbd_store_chunk_size 4
openstack-config --set /etc/cinder/cinder.conf ceph backend_host volumes
</pre>
<pre>
cinder-manage db sync
chown -R cinder:cinder /etc/cinder/ /var/lib/cinder/ /var/log/cinder/
for id in openstack-cinder-{api,scheduler,volume};do systemctl enable $id;systemctl start $id;done
scp /etc/cinder/cinder.conf node2:/etc/cinder ## 修改存储地址和bind地址
scp /etc/cinder/cinder.conf node3:/etc/cinder
ssh node2 chown -R cinder.cinder /etc/cinder /var/lib/cinder/ /var/log/cinder/
ssh node3 chown -R cinder.cinder /etc/cinder /var/lib/cinder/ /var/log/cinder/
ssh node2 for id in openstack-cinder-{api,scheduler,volume};do systemctl enable $id;systemctl start $id;done
ssh node3 for id in openstack-cinder-{api,scheduler,volume};do systemctl enable $id;systemctl start $id;done
cinder list
cinder create 1
</pre>


## ceph
<pre>
192.168.122.1	storage1
192.168.122.2	storage2
192.168.122.3	storage3
</pre>
<pre>
yum install ceph -y
[root@node1 yum.repos.d(keystone_admin_v3)]$cat /etc/ceph/ceph.conf 
[global]
fsid = 97e61689-e729-45b7-baa8-7e1a36b6b863
public network = 192.168.122.0/24
cluster network = 192.168.122.0/24
auth cluster required = cephx
auth service required = cephx
auth client required = cephx
mon initial members = node1, node2, node3 
mon host = 192.168.122.1, 192.168.122.2, 192.168.122.3 
osd pool default size = 3
osd pool default min size = 1
osd pool default pg num = 333
osd pool default pgp num = 333
osd crush chooseleaf type = 1
ms_type=async
debug_lockdep = 0/0
debug_context = 0/0
debug_crush = 0/0
debug_buffer = 0/0
debug_timer = 0/0
debug_filer = 0/0
debug_objecter = 0/0
debug_rados = 0/0
debug_rbd = 0/0
debug_journaler = 0/0
debug_objectcatcher = 0/0
debug_client = 0/0
debug_osd = 0/0
debug_optracker = 0/0
debug_objclass = 0/0
debug_filestore = 0/0
debug_journal = 0/0
debug_ms = 0/0
debug_monc = 0/0
debug_tp = 0/0
debug_auth = 0/0
debug_finisher = 0/0
debug_heartbeatmap = 0/0
debug_perfcounter = 0/0
debug_asok = 0/0
debug_throttle = 0/0
debug_mon = 0/0
debug_paxos = 0/0
debug_rgw = 0/0
</pre>
<pre>
ceph-authtool --create-keyring /etc/ceph/ceph.mon.keyring --gen-key -n mon. --cap mon 'allow *'
ceph-authtool --create-keyring /etc/ceph/ceph.client.admin.keyring --gen-key -n client.admin --set-uid=0 --cap mon 'allow *' --cap osd 'allow *' --cap mds 'allow'
ceph-authtool /etc/ceph/ceph.mon.keyring --import-keyring /etc/ceph/ceph.client.admin.keyring
monmaptool --create --add  storage1 192.168.122.1 --add storage2 192.168.122.2 --add storage3 192.168.122.3 --fsid 97e61689-e729-45b7-baa8-7e1a36b6b863 /etc/ceph/monmap
scp -r /etc/ceph/* storage2:/etc/ceph
scp -r /etc/ceph/* storage3:/etc/ceph
</pre>
ceph monitor安装(三个节点)
<pre>
export HOSTNAME=storage{1,2,3}
ceph-mon --mkfs -i $HOSTNAME --monmap /etc/ceph/monmap --keyring /etc/ceph/ceph.mon.keyring
touch /var/lib/ceph/mon/ceph-$HOSTNAME/done
systemctl enable ceph-mon@$HOSTNAME
systemctl start ceph-mon@$HOSTNAM
</pre>
ceph osd安装(三个节点)
storage1
<pre>
ceph-disk prepare /dev/sdb
ceph-disk activate /dev/sdb1
</pre>
storage2
<pre>
ceph-disk prepare /dev/sdb
ceph-disk activate /dev/sdb1
</pre>
storage3
<pre>
ceph-disk prepare /dev/sdb
ceph-disk activate /dev/sdb1
</pre>
ceph配置openstack的资源池(storage1)
<pre>
ceph osd pool create images 3 3
ceph auth get-or-create client.glance mon 'allow r' osd 'allow class-read object_prefix rbd_children, allow rwx pool=images'
ceph auth get-or-create client.glance | tee /etc/ceph/ceph.client.glance.keyring
scp /etc/ceph/ceph.client.glance.keyring node2:/etc/ceph
scp /etc/ceph/ceph.client.glance.keyring node3:/etc/ceph
ceph osd pool create volumes 3 3
ceph auth get-or-create client.cinder mon 'allow r' osd 'allow class-read object_prefix rbd_children, allow rwx pool=volumes, allow rwx pool=vms, allow rwx pool=images'
ceph auth get-or-create client.cinder | tee /etc/ceph/ceph.client.cinder.keyring
chown cinder.cinder /etc/ceph/ceph.client.cinder.keyring
scp /etc/ceph/ceph.client.cinder.keyring node2:/etc/ceph
scp /etc/ceph/ceph.client.cinder.keyring node3:/etc/ceph
ssh node2 chown cinder.cinder /etc/ceph/ceph.client.cinder.keyring
ssh node3 chown cinder.cinder /etc/ceph/ceph.client.cinder.keyring
</pre>